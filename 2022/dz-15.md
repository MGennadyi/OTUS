# Greenplum
###### Оф.требования ubuntu-18, 20 нет.
```
cat /etc/lsb-release
# или
cat /etc/os-release
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=20.04
DISTRIB_CODENAME=focal
```
```
vim /etc/hosts
10.128.0.51 gp1.ru-central1.internal gp1
10.128.0.52 gp2.ru-central1.internal gp2
10.128.0.53 gp3.ru-central1.internal gp3
10.128.0.54 gp4.ru-central1.internal gp4
```
###### Правим репозиторий:
```
sudo vim /etc/apt/sources.list
deb http://security.ubuntu.com/ubuntu xenial-security main
deb http://ppa.launchpad.net/greenplum/db/ubuntu bionic main
deb http://ru.archive.ubuntu.com/ubuntu bionic main
```
```
# Добавим ключики:
gpg --keyserver keyserver.ubuntu.com --recv 3C6FDC0C01D86213
gpg --export --armor 3C6FDC0C01D86213 | sudo apt-key add -

sudo apt update && sudo apt upgrade -y -q
```
```
# Создаем группу, юзера, пароль:
sudo groupadd gpadmin
sudo useradd gpadmin -r -m -g gpadmin
echo gpadmin:gpadmin123 | sudo chpasswd
# или так: 
sudo passwd gpadmin
```
```
# создаем ssh ключ (без фразы)  для связывания ВМ между собой:
sudo -u gpadmin ssh-keygen -t rsa -b 4096 -q -f /home/gpadmin/.ssh/id_rsa -N ''
# Даем пользователю gpadmin право на sudo:
sudo usermod -aG sudo gpadmin
```
###### Аристов: Установка из пакетов не сработает, т.к. на 20 ubuntu нет пакетов.
###### Создаем bash-скрипт
```
vim greenplum.sh
```
```
#! /bin/bash

# Check we are a root
if [ "$EUID" -ne 0 ]
    then echo "Please run this script as root"
    exit
fi

REPO="/etc/apt/sources.list.d/greenplum-ubuntu-db-bionic.list"
PIN="/etc/apt/preferences.d/99-greenplum"

echo "Add required repositories"
touch \$REPO
cat > \$REPO <<REPOS
deb http://ppa.launchpad.net/greenplum/db/ubuntu bionic main
deb http://ru.archive.ubuntu.com/ubuntu bionic main
REPOS

echo "Configure repositories"
touch \$PIN
cat > \$PIN <<PIN_REPO
Package: *
Pin: release v=18.04
Pin-Priority: 1
PIN_REPO

echo "Repositories described in \$REPO"
echo "Repositories configuration in \$PIN"
echo "Installing greenplum"
sudo apt update && sudo apt install greenplum-db-6 -y
```
```
# Права на выполнение и выполняем:
chmod +x greenplum.sh
sudo ./greenplum.sh
```
```
# Смотрим, что установилось:
dpkg-query -l
# Появился пакет: greenplum-db-6 
```
```
# выдадим права -R на каталог по умолчанию:
sudo find / -name "greenplum*"
# Нужный ответ: /opt/greenplum-db-6.21.0/greenplum_path.sh
sudo chown -R gpadmin:gpadmin /opt/greenplum*
```
```
sudo su gpadmin
$
bash
To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.
gpadmin@gp2:/home/mgb$
source /opt/greenplum-db-6.21.0/greenplum_path.sh
which gpssh
# Ответ:
/opt/greenplum-db-6.21.0/bin/gpssh
gpadmin@gp2:/home/mgb$
```
###### Выполняем скрипт первоначальной настройки через 'source' встройка кода в bach :
```
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
$PATH
sudo -u gpadmin source /opt/greenplum-db-6.21.0/greenplum_path.sh
# Ответ: sudo: source: command not found
# Прописалась ли переменная?:
which gpssh
# Ответа не должно быть
bash
gpadmin@gp1:vim /home/gpadmin/.bashrc
# Нужно наш sources прописать в .bashrc:
source /opt/greenplum-db-6.21.0/greenplum_path.sh
which gpssh
# Ответ: /opt/greenplum-db-6.21.0/bin/gpssh
exit
```
```
# Т.О. прописываем код в наш bash:
# По ниже команде по умолчанию попадаем не в bash, а в dash!:
root@gp:/home/mgb# sudo su gpadmin
# По этому выполняем:
$ bash
gpadmin@gp:/home/mgb$ source /opt/greenplum-db-6.21.0/greenplum_path.sh
gpadmin@gp:/home/mgb$ which gpssh
/opt/greenplum-db-6.21.0/bin/gpssh
exit
# Что бы не dash, а bash для этого:
sudo dpkg-reconfigure dash
pass: 12345
# Попадаем в окно конфига dash, отвечаем:
no
exit
# Если теперь зайти под пользователем gpadmin:
root@gp:/home/mgb# sudo su gpadmin
# Будет:
sh-5.0$
echo $shell
# Не помогло сменить dash на bash, т.к теперь идет запуск просто shell. Для bash меняем вручную:
chsh
Password: 12345
# Ответ:
        Login Shell [/bin/sh]: 
# Ввести:
/bin/bash
sh-5.0$
# теперь команды из-под пользователя gpadmin будут обрабатываться bash. 
# Проделаем то же самое на 2-4 ВМ, из под gpadmin:
sudo su gpadmin
# Прописываем source в bashrc:
echo "source /opt/greenplum-db-6.21.0/greenplum_path.sh" >> ~/.bashrc
# Меняем shell на bash;
chsh -s /bin/bash
pass: 12345
# Проверим, что все работает:
which gpssh
# Ответ:
/opt/greenplum-db-6.21.0/bin/gpssh
```
###### Прописать ssh друг у друга.Каждая нода ходила без пароля. Не работает:
```
sudo apt install ssh
ssh-copy-id gp2
yes
Permission denied (publickey).
```
###### Работает:
```
# Аристов: что бы ssh-copy-id разложил публичный ключ, исп. вход по паролю (потом лучше отключить):
# Можно вручную разложить, но пойдем так:
gpadmin@gp4:~$ sudo vim /etc/ssh/sshd_config
PasswordAuthentication no -> yes (в самом низу)
gpadmin@gp4:~$ sudo systemctl restart sshd
# Проделать на остальных вм: 
exit
root@gp:/home/mgb# sudo su gpadmin
gpadmin@gp:/home/mgb$ sudo vim /etc/ssh/sshd_config
[sudo] password for gpadmin:
gpadmin@gp:/home/mgb$ sudo systemctl restart sshd
# C gp1 Раскладываем ключ по другим ВМ из под gpadmin:
ssh-copy-id gp2
yes
pass: 12345
ssh-copy-id gp3
ssh-copy-id gp4
# C gp2 Раскладываем ключ по другим ВМ:
ssh-copy-id gp1
ssh-copy-id gp3
ssh-copy-id gp4
# C gp3 Раскладываем ключ по другим ВМ:
ssh-copy-id gp1
ssh-copy-id gp2
ssh-copy-id gp4
# C gp4 Раскладываем ключ по другим ВМ:
ssh-copy-id gp1
ssh-copy-id gp2
ssh-copy-id gp3
```
```
# На каждой ноде прописываем какие есть еще ноды: Если в домашнем каталоге gpadmin, то: 
sudo vim ~/hostfile_exkeys
# иначе:
sudo vim /home/gpadmin/hostfile_exkeys
gp1
gp2
gp3
gp4
```
###### Убеждаемся, что каждая нода видит других через утилиту gpssh-exkeys:
```
sudo vim /etc/apt/sources.list
sudo apt install libssl1.0.0 -y
cd ~
gpssh-exkeys -f hostfile_exkeys
# Ответ:
[STEP 1 of 5] create local ID and authorize on local host
  ... /home/gpadmin/.ssh/id_rsa file exists ... key generation skipped

[STEP 2 of 5] keyscan all hosts and update known_hosts file

[STEP 3 of 5] retrieving credentials from remote hosts
  ... send to gp2
  ... send to gp3
  ... send to gp4

[STEP 4 of 5] determine common authentication file content

[STEP 5 of 5] copy authentication files to all remote hosts
  ... finished key exchange with gp2
  ... finished key exchange with gp3
  ... finished key exchange with gp4

[INFO] completed successfully
gpadmin@gp1:~$
```
##### Подтвердить установку ssh:
```
cd ~
gpssh -f hostfile_exkeys -e 'ls -l /opt/greenplum-db-6.21.0'
# Можно увидеть на каких нодах какие каталоги доступны
```
###### На всех нодах создать каталог, где будут лежать наши данные: 'Data Storage Areas':
```
sudo mkdir -p /data/master
sudo chown gpadmin:gpadmin /data/master
```
```
# На сегментах, это ноды 3-4, отличаются доп.созданием /mirror и /primary:
sudo mkdir -p /data/primary
sudo mkdir -p /data/mirror
sudo chown -R gpadmin /data/*
```
###### Валидировать нашу установку и Инициализацию:
```
# На всех хостах создаем конфиг-файл, где указываем сегменты:
cd ~
vim ~/hostfile_gpinitsystem
# или
sudo vim /home/gpadmin/hostfile_gpinitsystem
gp3
gp4
```
```
cd ~
mkdir /home/gpadmin/gpconfigs
cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config \
     /home/gpadmin/gpconfigs/gpinitsystem_config

vim /home/gpadmin/gpconfigs/gpinitsystem_config
# Задаем и раскоментировать:
MASTER_HOSTNAME=gp1
MASTER_DIRECTORY=/data/master
MIRROR_PORT_BASE=7000
declare -a MIRROR_DATA_DIRECTORY=(/data/mirror)
# Заменить не верные директории без 1:
declare -a DATA_DIRECTORY=(/data1/primary /data1/primary /data1/primary /data2/primary /data2/primary /data2/primary)
```
###### Второй мастер уазывается при инициализации системы, и сразу включаем мирроринг:
```
cd ~
gpinitsystem -c gpconfigs/gpinitsystem_config -h hostfile_gpinitsystem -s gp2 --mirror-mode=spread
# Не заработает по причине: колич-во ностов должно быть больше кол-ва сегментов.
vim /home/gpadmin/gpconfigs/gpinitsystem_config
# Аристов: Кол-во хостов должно быть больше кол-ва сегментов, поэтому оставляем только 1 каталог с данными - непонятно действие:
declare -a DATA_DIRECTORY=(/data/primary)
declare -a MIRROR_DATA_DIRECTORY=(/data/mirror)
```
```
# Повторный запуск. Теперь должно заработать:
gpinitsystem -c gpconfigs/gpinitsystem_config -h hostfile_gpinitsystem -s gp2 --mirror-mode=spread
```
###### Длинная портянка сообщений:
```
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Checking new segment hosts, Completed
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Greenplum Database Creation Parameters
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:---------------------------------------
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master Configuration
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:---------------------------------------
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master instance name       = Greenplum Data Platform
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master hostname            = gp1
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master port                = 5432
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master instance dir        = /data/master/gpseg-1
20220729:11:26:17:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master LOCALE              = en_US.utf8
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Greenplum segment prefix   = gpseg
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master Database            =
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master connections         = 250
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master buffers             = 128000kB
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Segment connections        = 750
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Segment buffers            = 128000kB
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Checkpoint segments        = 8
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Encoding                   = UNICODE
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Postgres param file        = Off
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Initdb to be used          = /opt/greenplum-db-6.21.0/bin/initdb
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-GP_LIBRARY_PATH is         = /opt/greenplum-db-6.21.0/lib
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-HEAP_CHECKSUM is           = on
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-HBA_HOSTNAMES is           = 0
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[WARN]:-Ulimit check               = Warnings generated, see log file <<<<<
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Array host connect type    = Single hostname per node
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master IP address [1]      = ::1
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master IP address [2]      = 10.128.0.51
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Master IP address [3]      = fe80::d20d:9aff:fe87:8e2b
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Standby Master             = gp2
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Number of primary segments = 1
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Standby IP address         = ::1
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Standby IP address         = 10.128.0.52
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Standby IP address         = fe80::d20d:23ff:fef4:6d30
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Total Database segments    = 2
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Trusted shell              = ssh
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Number segment hosts       = 2
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Mirror port base           = 7000
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Number of mirror segments  = 1
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Mirroring config           = ON
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Mirroring type             = Spread
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:----------------------------------------
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Greenplum Primary Segment Configuration
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:----------------------------------------
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-gp3   6000    gp3     /data/primary/gpseg0    2
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-gp4   6000    gp4     /data/primary/gpseg1    3
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:---------------------------------------
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-Greenplum Mirror Segment Configuration
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:---------------------------------------
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-gp4   7000    gp4     /data/mirror/gpseg0     4
20220729:11:26:18:004451 gpinitsystem:gp1:gpadmin-[INFO]:-gp3   7000    gp3     /data/mirror/gpseg1     5
Continue with Greenplum creation Yy|Nn (default=N):
y
```
```
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:------------------------------------------------
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Parallel process exit status
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:------------------------------------------------
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Total processes marked as completed           = 2
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Total processes marked as killed              = 0
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Total processes marked as failed              = 0
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:------------------------------------------------
20220729:11:30:46:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Starting initialization of standby master gp2
20220729:11:30:46:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Validating environment and parameters for standby initialization...
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Checking for data directory /data/master/gpseg-1 on gp2
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:------------------------------------------------------
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum standby master initialization parameters
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:------------------------------------------------------
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum master hostname               = gp1
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum master data directory         = /data/master/gpseg-1
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum master port                   = 5432
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum standby master hostname       = gp2
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum standby master port           = 5432
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum standby master data directory = /data/master/gpseg-1
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Greenplum update system catalog         = On
20220729:11:30:47:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Syncing Greenplum Database extensions to standby
20220729:11:30:48:009126 gpinitstandby:gp1:gpadmin-[INFO]:-The packages on gp2 are consistent.
20220729:11:30:48:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Adding standby master to catalog...
20220729:11:30:48:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Database catalog updated successfully.
20220729:11:30:48:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Updating pg_hba.conf file...
20220729:11:30:49:009126 gpinitstandby:gp1:gpadmin-[INFO]:-pg_hba.conf files updated successfully.
20220729:11:30:53:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Starting standby master
20220729:11:30:53:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Checking if standby master is running on host: gp2  in directory: /data/master/gpseg-1
20220729:11:30:58:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Cleaning up pg_hba.conf backup files...
20220729:11:30:58:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Backup files of pg_hba.conf cleaned up successfully.
20220729:11:30:58:009126 gpinitstandby:gp1:gpadmin-[INFO]:-Successfully created standby master on gp2
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Successfully completed standby master initialization
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Scanning utility log file for any warning messages
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[WARN]:-*******************************************************
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[WARN]:-Scan of log file indicates that some warnings or errors
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[WARN]:-were generated during the array creation
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Please review contents of log file
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-/home/gpadmin/gpAdminLogs/gpinitsystem_20220729.log
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-To determine level of criticality
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-These messages could be from a previous run of the utility
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-that was called today!
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[WARN]:-*******************************************************
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Greenplum Database instance successfully created
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-------------------------------------------------------
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-To complete the environment configuration, please
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-update gpadmin .bashrc file with the following
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-1. Ensure that the greenplum_path.sh file is sourced
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-2. Add "export MASTER_DATA_DIRECTORY=/data/master/gpseg-1"
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-   to access the Greenplum scripts for this instance:
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-   or, use -d /data/master/gpseg-1 option for the Greenplum scripts
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-   Example gpstate -d /data/master/gpseg-1
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Script log file = /home/gpadmin/gpAdminLogs/gpinitsystem_20220729.log
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-To remove instance, run gpdeletesystem utility
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Standby Master gp2 has been configured
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-To activate the Standby Master Segment in the event of Master
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-failure review options for gpactivatestandby
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-------------------------------------------------------
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-The Master /data/master/gpseg-1/pg_hba.conf post gpinitsystem
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-has been configured to allow all hosts within this new
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-array to intercommunicate. Any hosts external to this
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-new array must be explicitly added to this file
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-Refer to the Greenplum Admin support guide which is
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-located in the /opt/greenplum-db-6.21.0/docs directory
20220729:11:30:58:005782 gpinitsystem:gp1:gpadmin-[INFO]:-------------------------------------------------------
gpadmin@gp1:~$
```
###### Проверка состояния через внесения:
```
vim ~/.bashrc
MASTER_DATA_DIRECTORY=/opt/data/master/gpseg-1
export MASTER_DATA_DIRECTORY
gpstate
```
##### После рестарта всех нод, на мастер-ноде:
```
gpstart
# Прописать 
vim ~/.bashrc
MASTER_DATA_DIRECTORY=/opt/data/master/gpseg-1
export MASTER_DATA_DIRECTORY
echo ~/.bashrc
```
###### Вход в postgresql:
```
gpadmin@gp1:~$ psql
psql: FATAL:  database "gpadmin" does not exist
gpadmin@gp1:~$ psql -d postgres
psql (9.4.26)
postgres=# \l
                               List of databases
   Name    |  Owner  | Encoding |  Collate   |   Ctype    |  Access privileges
-----------+---------+----------+------------+------------+---------------------
 postgres  | gpadmin | UTF8     | en_US.utf8 | en_US.utf8 |
 template0 | gpadmin | UTF8     | en_US.utf8 | en_US.utf8 | =c/gpadmin         +
           |         |          |            |            | gpadmin=CTc/gpadmin
 template1 | gpadmin | UTF8     | en_US.utf8 | en_US.utf8 | =c/gpadmin         +
           |         |          |            |            | gpadmin=CTc/gpadmin
```
```
# Зальем данные:
cd $HOME && wget --quiet https://edu.postgrespro.ru/demo_small.zip && unzip demo_small.zip && psql -d postgres < demo_small.sql
\l+

```
```
psql -d demo
\l+
# смотрим схему bookings, которая не включена в путь
\dt+ bookings.*
```
```

```
```
# Данных нет
select * from flights2;
INSERT INTO flights2 SELECT * FROM bookings.flights;
```


