# Кластер Patroni on-premise.
##### 0. Установка postgresql-14.
##### 1. Установка ETCD:
```
sudo apt update && sudo apt upgrade -y
--apt purge etcd -y
--apt purge etcd-server -y
--apt purge etcd-client -y
apt install etcd -y
systemctl stop etcd
rm -rf /var/lib/etcd/member/snap/*
rm -rf /var/lib/etcd/member/wal/*
ls -l /var/lib/
sudo chown -R etcd /var/lib/etcd
> /etc/default/etcd
vim /etc/default/etcd
```
###### Внутренние ноды на статич.адресах, доменные имена полностью:
```
vim /etc/hostname
etcd1.ru-central1.internal
etcd2.ru-central1.internal 
etcd3.ru-central1.internal 
```
```
ETCD_NAME="etcd1.ru-central1.internal"
ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
ETCD_ADVERTISE_CLIENT_URLS="http://10.128.0.20:2379"
ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://10.128.0.20:2380"
ETCD_INITIAL_CLUSTER_TOKEN="PatroniCluster"
ETCD_INITIAL_CLUSTER="etcd1.ru-central1.internal=http://10.128.0.20:2380,etcd2.ru-central1.internal=http://10.128.0.16:2380,etcd3.ru-central1.internal=http://10.128.0.27:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_DATA_DIR="/var/lib/etcd"
ETCD_ELECTION_TIMEOUT="5000"
ETCD_HEARTBEAT_INTERVAL="1000"
```
```
ETCD_NAME="etcd3.ru-central1.internal"
ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
ETCD_ADVERTISE_CLIENT_URLS="http://10.128.0.27:2379"
ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://10.128.0.27:2380"
ETCD_INITIAL_CLUSTER_TOKEN="PatroniCluster"
ETCD_INITIAL_CLUSTER="etcd1.ru-central1.internal=http://10.128.0.20:2380,etcd2.ru-central1.internal=http://10.128.0.16:2380,etcd3.ru-central1.internal=http://10.128.0.27:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_DATA_DIR="/var/lib/etcd"
ETCD_ELECTION_TIMEOUT="5000"
ETCD_HEARTBEAT_INTERVAL="1000"
```
```
systemctl status etcd
systemctl start etcd
systemctl is-enabled etcd
etcdctl cluster-health
etcdctl member list


sudo etcdctl member add etcd2 http://192.168.5.163:2380

```
##### 2. Установка PATRONI

```
sudo passwd root
12345

sudo apt-get install gnupg1 gnupg2 -y
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
sudo wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt update
sudo apt-get install postgresql-14 -y
pg_isready
systemctl status postgresql
-- systemctl start postgresql
-- systemctl stop postgresql
sudo apt-get install -y python3 python3-pip git
sudo pip3 install psycopg2-binary
systemctl stop postgresql
sudo -u postgres pg_dropcluster 14 main
sudo systemctl daemon-reload
pg_dropcluster 14 main
pg_isready
pg_lsclusters
sudo pip3 install patroni[etcd]
sudo ln -s /usr/local/bin/patroni /bin/patroni
```
```
sudo vim /etc/systemd/system/patroni.service
```
```
[Unit]
Description=High availability PostgreSQL Cluster
After=syslog.target network.target

[Service]
Type=simple
User=postgres
Group=postgres
ExecStart=/usr/local/bin/patroni /etc/patroni.yml
KillMode=process
TimeoutSec=30
Restart=always

[Install]
WantedBy=multi-user.target
```
###### Вставляем в patroni.yml свой вариант конфига для каждой ноды.
```
sudo vim /etc/patroni.yml
```
###### Бутстрапим:
```
sudo -u postgres patroni /etc/patroni.yml
```
###### Исправляем ошибку. В секции postgresql указываем путь к бинарникам: bin_dir: /usr/lib/postgresql/14/bin
###### Ответ: INFO: no action. I am (pg3), a secondary, and following a leader (pg1)
###### Проверим, изменим состояние запуска patroni и стартуем его как сервис:
```
sudo systemctl is-enabled patroni
sudo systemctl enable patroni
# Ответ: Created symlink /etc/systemd/system/multi-user.target.wants/patroni.service → /etc/systemd/system/patroni.service.
sudo systemctl restart patroni
sudo systemctl status patroni
# ВАЖНО:  не удалось начать трансляцию WAL: ОШИБКА:  слот репликации "pg3" не существует
sudo patronictl -c /etc/patroni.yml list
```
Member|Host|Role|State|Tl|Lag in MB|
:----|:--------:|-----:|-----:|-----:|-----:
pg1|192.168.5.165|Leader  |Running|1| |
pg2|192.168.5.166|Replica |Running|1|0|
pg3|192.168.5.167|Replica |Running|1|0|
```
sudo patronictl -c /etc/patroni.yml restart postgres
Error: postgres cluster doesn't have any members
```
###### Если поронять: на мастере pg1:
```
systemctl stop patroni
```
###### На pg2:
```
root@pg2:/home/mgb# sudo patronictl -c /etc/patroni.yml list
+--------+---------------+---------+---------+----+-----------+
| Member | Host          | Role    | State   | TL | Lag in MB |
+ Cluster: patroni (7114613472625263394) ----+----+-----------+
| pg1    | 192.168.5.165 | Replica | stopped |    |   unknown |
| pg2    | 192.168.5.166 | Leader  | running |  3 |           |
| pg3    | 192.168.5.167 | Replica | running |  3 |         0 |
+--------+---------------+---------+---------+----+-----------+
root@pg2:/home/mgb# sudo patronictl -c /etc/patroni.yml list
+--------+---------------+---------+---------+----+-----------+
| Member | Host          | Role    | State   | TL | Lag in MB |
+ Cluster: patroni (7114613472625263394) ----+----+-----------+
| pg2    | 192.168.5.166 | Leader  | running |  3 |           |
| pg3    | 192.168.5.167 | Replica | running |  3 |         0 |
+--------+---------------+---------+---------+----+-----------+
```
###### На выбывшем мастере pg1:
```
systemctl start patroni
sudo patronictl -c /etc/patroni.yml list
+--------+---------------+---------+---------+----+-----------+
| Member | Host          | Role    | State   | TL | Lag in MB |
+ Cluster: patroni (7114613472625263394) ----+----+-----------+
| pg1    | 192.168.5.165 | Replica | running | 10 |         0 |
| pg2    | 192.168.5.166 | Leader  | running | 10 |           |
| pg3    | 192.168.5.167 | Replica | running | 10 |         0 |
+--------+---------------+---------+---------+----+-----------+
```
###### Patroni отрабатывает потерю возвращение обной ноды. Далее:

#### Pg_Bouncer. Создается на всех 3-х нодах:
```
sudo apt install -y pgbouncer
sudo systemctl status pgbouncer
sudo systemctl stop pgbouncer
# логи пишутся в другое место, 2 позиции пропускаем:
-- sudo mkdir /var/log/pgbouncer
-- sudo chown -R postgres /var/log/pgbouncer
vim /etc/pgbouncer/pgbouncer.ini
```
```
[databases]
otus = host=127.0.0.1 port=5432 dbname=otus 
[pgbouncer]
logfile = /var/log/postgresql/pgbouncer.log
pidfile = /var/run/postgresql/pgbouncer.pid
listen_addr = *
listen_port = 6432
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
admin_users = admindb
# В дальнейшем Аристов заменил на 
admin_users = postgres
```
###### На pg3
```
sudo -u postgres psql -h localhost
# Пробуем создать базу
create database otus;
# ОШИБКА: режим "только чтение" - это же реплика!
```
###### На master pg2:
```
sudo -u postgres psql -h localhost
create database otus;
```
###### Проверка создания БД OTUS на реплике на pg3. 
```
\l
    Имя    | Владелец | Кодировка | LC_COLLATE  |  LC_CTYPE   |     Права доступа
-----------+----------+-----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8      | ru_RU.UTF-8 | ru_RU.UTF-8 |
 postgres  | postgres | UTF8      | ru_RU.UTF-8 | ru_RU.UTF-8 |
 template0 | postgres | UTF8      | ru_RU.UTF-8 | ru_RU.UTF-8 | =c/postgres          +
           |          |           |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8      | ru_RU.UTF-8 | ru_RU.UTF-8 | =c/postgres          +
           |          |           |             |             | postgres=CTc/postgres
```
###### На всех нодах добавляем пароль admindb в формате md5 в userlist.txt
```
sudo -u postgres psql -h localhost
create user admindb with password '12345';
\du
select * from pg_user;
select usename, passwd from pg_shadow;
# Копируем хеш пароля
vim /etc/pgbouncer/userlist.txt
"postgres"  "SCRAM-SHA-256$4096:5QzE5QKo/Y0sUSKxIIhmBA==$mViw6DFyxLkcRRDyft3UOoJ/JGw5zRyvpOJnkt+EtmI=:8gi9vxsVajxpmcVZb3gqjnecPeXoel/eBqk3pEbbX7k="
```
###### Как запущен pgbouncer? Как демон или служба?
```
su postgres
ps -xf
3286 ?        Ssl    0:02 /usr/sbin/pgbouncer /etc/pgbouncer/pgbouncer.ini
kill 3286
sudo systemctl start pgbouncer
su postgres
ps -xf
3996 ?        Ssl    0:00 /usr/sbin/pgbouncer /etc/pgbouncer/pgbouncer.ini
sudo -u postgres -p 6432 -h 127.0.0.1 otus
sudo -u postgres psql -p 6432 -h 127.0.0.1 otus
# ввести passwd= zalando_321
```
###### Нагрузим с pg1 на pg2  192.168.5.166:
```
sudo -u postgres pgbench -p 6432 -c 20 -C -T 60 -P 1 -d otus -h 192.168.5.166

# Аристов: если указать не сущ.бд, то pgbouncer умрет. Небходимо включить рестарт сервиса при падении Restart=always
```
###### Админка pgbouncera
```
sudo -u postgres psql -p 6432 pgbouncer -h localhost
show clients;
 type |   user   | database  | state  | addr | port  | local_addr | local_port |      connect_time       |      request_time       | wait | wait_us | close_needed |      ptr       | link | remote_pid | tls
------+----------+-----------+--------+------+-------+------------+------------+-------------------------+-------------------------+------+---------+--------------+----------------+------+------------+-----
 C    | postgres | pgbouncer | active | ::1  | 51976 | ::1        |       6432 | 2022-07-01 13:35:24 MSK | 2022-07-01 13:35:36 MSK |    0 |       0 |            0 | 0x564fa861a780 |      |          0 |

```
##### HA PROXY - балансир нагрузки: пишем на мастер, читаем со slave:
###### С новых 2-х нод тестим ответ :
```
curl -v 192.168.5.165:8008/replica
# HTTP/1.0 200 OK
curl -v 192.168.5.166:8008/master
# HTTP/1.0 200 OK
```
```
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
sudo wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt update
sudo apt install postgresql-client -y
sudo apt install -y haproxy
sudo vim /etc/haproxy/haproxy.cfg
```
```
listen postgres_write
    bind *:5432
    mode            tcp
    option httpchk
    http-check connect
    http-check send meth GET uri /master
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg1 192.168.5.165:6432 check port 8008
    server pg2 192.168.5.166:6432 check port 8008
    server pg3 192.168.5.167:6432 check port 8008

listen postgres_read
    bind *:5433
    mode            tcp
    http-check connect
    http-check send meth GET uri /replica
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg1 192.168.5.165:6432 check port 8008
    server pg2 192.168.5.166:6432 check port 8008
    server pg3 192.168.5.167:6432 check port 8008
```
```
sudo systemctl restart haproxy.service
sudo systemctl status haproxy.service
```
```
# Проверим все рабчее, c proxy на мастере:
psql -p 6432 -d otus -h 192.168.5.166 -U postgres
create database haproxy;
\q
# Подключение без указания master/replica:
psql -h localhost -d otus -U postgres -p 5432
create database haproxy;
```
###### Тестим на switchover:
```
sudo patronictl -c /etc/patroni.yml switchover

```























###### !!! Если поломался старый кластер
```
patronictl -c /etc/patroni.yml remove 7088634863084761990
```
